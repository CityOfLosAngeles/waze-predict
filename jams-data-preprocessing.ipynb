{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from json import loads\n",
    "from ast import literal_eval\n",
    "import glob\n",
    "import random\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from pathlib import Path\n",
    "from sklearn.neighbors import BallTree\n",
    "from IPython.display import clear_output\n",
    "import timeit\n",
    "from numba import jit\n",
    "from dask import dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "from multiprocessing import cpu_count\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all cores from desktop when performing parallel processing\n",
    "nCores = cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variable, if it exists\n",
    "def deleteIfExists(df):\n",
    "    try:\n",
    "        df\n",
    "    except NameError:\n",
    "        return False\n",
    "    else:\n",
    "        del df\n",
    "        return True # successfully deleted variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct malformed json in Jams dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to input file\n",
    "filepath = 'data/jams-head.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create valid dataset\n",
    "with open(f'{filepath}') as in_file:\n",
    "    with open(f'{filepath[:-4]}-valid.csv', 'w') as out_file:\n",
    "        for line in in_file:\n",
    "            out_line = []\n",
    "            \n",
    "            is_list = 0\n",
    "            in_quotes = False\n",
    "            is_json = False # flag to track if reading JSON body\n",
    "\n",
    "            for c in line: # c = char\n",
    "                # \"[{'\"x'\": -118.342949, '\"y'\": 34.078279}, ...]\"\n",
    "                if c is '[':\n",
    "                    out_line[-1] = \"'\" # replace first \" to '\n",
    "                    out_line.append(c)\n",
    "                    is_json = True\n",
    "                    continue\n",
    "                elif c is ']':\n",
    "                    out_line.append(c)\n",
    "                    is_list = 1 # at closing bracket\n",
    "                    is_json = False\n",
    "                    continue\n",
    "                    \n",
    "                # preserve \"Los Angeles, CA\" so comma doesn't become a tab\n",
    "                elif c is '\"': \n",
    "                    if not in_quotes:\n",
    "                        in_quotes = True\n",
    "                    else:\n",
    "                        in_quotes = False\n",
    "                \n",
    "                # change \" to ' at end of list\n",
    "                if is_list is 1:\n",
    "                    out_line += \"'\"\n",
    "                    is_list = 2 # done processing json\n",
    "                    continue\n",
    "                    \n",
    "                # reconstruct line to write to  file\n",
    "                if not is_json:\n",
    "                    if c is not ',':\n",
    "                        out_line.append(c)\n",
    "                    else:\n",
    "                        if not in_quotes:\n",
    "                            out_line.append('\\t')\n",
    "                        else:\n",
    "                            out_line.append(c)\n",
    "                elif is_json and (c is not \"\\'\"): # skip the double quote that creates invalid json\n",
    "                    out_line.append(c)\n",
    "                elif is_json and (c is '\\''): # pass inconsistent pattern\n",
    "                    pass\n",
    "            \n",
    "            # output each row to file\n",
    "            out_file.write(''.join(out_line[:-1]) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load valid data into dataframe\n",
    "df = pd.DataFrame()\n",
    "df = pd.read_csv(f'{filepath[:-4]}-valid.csv', sep='\\t', header=None)\n",
    "df.columns = ['primary_id1','primary_id2','pub_millis','pub_utc_date','unknown1','start_node','road_type','end_node','interm_city','country','delay_seconds','avg_speed','speed_kmh','length_meter','turn_type','level','blocking_alert_uuid','line','traffic_type','turn_line','unknown2','datafile_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate relevant data\n",
    "df = df[['pub_millis', 'avg_speed', 'line']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to datetime object\n",
    "df['pub_millis'] = pd.to_datetime(df['pub_millis'], unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save state 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/jams-refined.csv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition Jams into smaller datasets to process easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteIfExists(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('data/jams-refined.csv', sep='\\t', header=None)\n",
    "df.columns = ['pub_millis', 'avg_speed', 'line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total number of rows in dataframe\n",
    "df_length = df.count()\n",
    "\n",
    "# create arbitrary partition size\n",
    "n = df_length * 0.3\n",
    "\n",
    "file_num = 1\n",
    "\n",
    "# define starting and ending spliced index for dataframe\n",
    "starting_index = 0\n",
    "ending_index = n\n",
    "\n",
    "# while the end index is not out of bounds\n",
    "while ending_index <= df_length:\n",
    "    # splice the dataframe and save the partitions\n",
    "    df.iloc[starting_index:ending_index].to_csv(f'data/jams-partition-{file_num}.csv', sep='\\t', index=False, header=False)\n",
    "    \n",
    "    file_num += 1\n",
    "    starting_index = ending_index\n",
    "    \n",
    "    if ending_index + n > df_length:\n",
    "        ending_index = df_length\n",
    "    else:\n",
    "        ending_index += n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process each Jams partition\n",
    "These following steps will be repeated until all partitions complete save state 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num = 1\n",
    "df = pd.DataFrame()\n",
    "df = pd.read_csv(f'data/jams-partition-{file_num}.csv', sep='\\t', header=None)\n",
    "\n",
    "# pub_millis: dateobject, avg_speed: float, line: list of dict\n",
    "df.columns = ['pub_millis', 'avg_speed', 'line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-10 23:57:34.974</td>\n",
       "      <td>5.89444</td>\n",
       "      <td>'[{\"x\": -118.271445, \"y\": 34.062425}, {\"x\": -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>'[{\"x\": -118.273876, \"y\": 34.072198}, {\"x\": -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-11 00:42:26.705</td>\n",
       "      <td>1.27778</td>\n",
       "      <td>'[{\"x\": -118.271838, \"y\": 34.06928}, {\"x\": -11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-10 22:45:14.498</td>\n",
       "      <td>1.78889</td>\n",
       "      <td>'[{\"x\": -118.260378, \"y\": 34.078331}, {\"x\": -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-11 00:47:49.429</td>\n",
       "      <td>5.55556</td>\n",
       "      <td>'[{\"x\": -118.261324, \"y\": 34.076332}, {\"x\": -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pub_millis  avg_speed  \\\n",
       "0  2018-04-10 23:57:34.974    5.89444   \n",
       "1  2018-04-11 00:30:30.955    4.35000   \n",
       "2  2018-04-11 00:42:26.705    1.27778   \n",
       "3  2018-04-10 22:45:14.498    1.78889   \n",
       "4  2018-04-11 00:47:49.429    5.55556   \n",
       "\n",
       "                                                line  \n",
       "0  '[{\"x\": -118.271445, \"y\": 34.062425}, {\"x\": -1...  \n",
       "1  '[{\"x\": -118.273876, \"y\": 34.072198}, {\"x\": -1...  \n",
       "2  '[{\"x\": -118.271838, \"y\": 34.06928}, {\"x\": -11...  \n",
       "3  '[{\"x\": -118.260378, \"y\": 34.078331}, {\"x\": -1...  \n",
       "4  '[{\"x\": -118.261324, \"y\": 34.076332}, {\"x\": -1...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map waze coordinates to edges from graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load road network of Los Angeles City\n",
    "G = ox.graph_from_place('Los Angeles City, Los Angeles, CA',network_type='drive')\n",
    "gdf, _ = ox.graph_to_gdfs(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({0: {'osmid': 13397064, 'name': 'Knox Street', 'highway': 'residential', 'oneway': False, 'length': 417.085}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check specific edge from road network\n",
    "G[402279372][123306201]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip to Ball Tree if node.csv, segment.csv, selSegs_1.csv are already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node.csv contains all the intersections in LA\n",
    "# header: osm_id, latitude, longitude\n",
    "with open('data/node.csv', 'w') as out_file:\n",
    "    for osm_id in G.node:\n",
    "        node = G.node[osm_id]\n",
    "        out_file.write(f\"{osm_id},{node['y']},{node['x']}\\n\")\n",
    "\n",
    "                       \n",
    "# segment.csv contains all of the road segments in LA\n",
    "# header: pseudo_edge_id, start_osmid, end_osmid\n",
    "osm_edge_ids = nx.edges(G)\n",
    "row_counter = 0\n",
    "edge_dict = {}\n",
    "                       \n",
    "with open('data/segment.csv', 'w') as out_file:\n",
    "    for x, y in osm_edge_ids:\n",
    "        # prevent duplicated edges from getting added to the segments file\n",
    "        if (x, y) not in edge_dict:\n",
    "            out_file.write(f'{row_counter},{x},{y}\\n')\n",
    "            edge_dict[(x, y)] = row_counter\n",
    "            row_counter += 1\n",
    "\n",
    "del edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load segment.csv data\n",
    "segments = {}\n",
    "with open('data/segment.csv') as in_file:\n",
    "    for line in in_file:\n",
    "        split_line = line.rstrip().split(',')\n",
    "        \n",
    "        # set (node tuple)-key in dict to its (rowid)-value\n",
    "        segments[(int(split_line[1]), int(split_line[2]))] = int(split_line[0])\n",
    "\n",
    "# v: pseudo-edge id\n",
    "# k: start and end nodes\n",
    "inverted_segments = {v: k for k, v in segments.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4214, 6273, 6274, 7997, 14074, 15945, 15969, 15971, 22813, 26311, 26312, 33369, 33370, 41472, 41496, 41497, 41498, 42385, 42386, 58386, 58387, 58388, 59425, 59426, 59447, 59448, 59449, 59456, 59457, 59495, 59496, 60896, 60898, 61634, 61635, 63069, 63235, 63236, 63245, 63246, 63247, 63248, 68997, 68998, 68999, 69733, 69735, 69736, 70702, 70703, 73873, 73874, 77168, 77169, 77174, 77176, 82431, 83352, 83353, 83812, 83813, 84020, 84021, 86817, 86819, 86820, 86822, 86823, 86824, 88491, 88492, 88493, 88827, 89808, 89809, 90175, 90176, 90177, 90178, 90442, 90443, 90444, 90537, 94602, 94603, 94604, 106473, 108638, 109253, 109255, 109256, 118097, 120242, 120243, 120247, 120286, 120287, 120555, 120556, 120563, 120564, 120572, 120573, 132535, 132536, 132543, 132544, 132545, 134117, 134118, 134177]\n"
     ]
    }
   ],
   "source": [
    "# get list of edge ids that exist in the financial district\n",
    "fin_g = ox.graph_from_place('Financial District, Los Angeles, CA',network_type='drive')\n",
    "district_edge_ids = []\n",
    "\n",
    "for x, y in nx.edges(fin_g):\n",
    "    district_edge_ids.append(segments[(x, y)])\n",
    "district_edge_ids.sort()\n",
    "\n",
    "print(district_edge_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selSegs_1.csv contains the road segments of interest for prediction\n",
    "with open('data/selSegs_1.csv', 'w') as out_file:\n",
    "    for edge_id in district_edge_ids:\n",
    "        out_file.write(f'{edge_id}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ball Tree. This section maps coordinates from Waze linestrings to the closest intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Ball Tree algorithm using osm road network\n",
    "ball_tree = BallTree(gdf[['y', 'x']], metric='haversine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edges(nodes):\n",
    "    edges = []\n",
    "    \n",
    "    for i in range(len(nodes) - 1):\n",
    "        if (nodes[i], nodes[i+1]) in segments:\n",
    "            edges.append((nodes[i], nodes[i+1]))    \n",
    "            \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit #numba magic\n",
    "def map_edges(line_string):\n",
    "    closest_nodes = []\n",
    "    \n",
    "    # store coordinates in line\n",
    "    line = loads(line_string.replace('\\'', ''))\n",
    "    \n",
    "    # iterate over each coordinate in line to get closest nodes\n",
    "    for coordinate in line:\n",
    "        _, indexes = ball_tree.query([[coordinate['y'], coordinate['x']]])\n",
    "        closest_nodes.append(int(gdf.iloc[indexes[0]].osmid.tolist()[0]))\n",
    "    \n",
    "    # get all unique closest nodes\n",
    "    closest_nodes = list(set(closest_nodes))\n",
    "    \n",
    "    return create_edges(closest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 14hr 28min 46.8s\n"
     ]
    }
   ],
   "source": [
    "# parallelize using dask and numba\n",
    "res = dd.from_pandas(df,npartitions=nCores).map_partitions(\n",
    "    lambda _df : _df.apply(\n",
    "        lambda x : map_edges(x.line),axis=1), meta=('edges','i8'))\n",
    "\n",
    "# print progress of parallelization\n",
    "with ProgressBar(dt=0.01):\n",
    "    out = res.compute(scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21690695                                                  []\n",
       "21690696    [(122532560, 122735795), (123129231, 122527731)]\n",
       "21690697                                                  []\n",
       "21690698                                                  []\n",
       "21690699                                                  []\n",
       "Name: edges, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results from parallelization\n",
    "out.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store output from map_edges into the edges column\n",
    "df['edges'] = pd.Series(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete linestring column now that we have the edges\n",
    "del df['line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21690695</th>\n",
       "      <td>2018-07-06 17:28:12.166</td>\n",
       "      <td>7.35278</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21690696</th>\n",
       "      <td>2018-07-06 17:28:12.867</td>\n",
       "      <td>1.77222</td>\n",
       "      <td>[(122532560, 122735795), (123129231, 122527731)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21690697</th>\n",
       "      <td>2018-07-06 16:18:23.454</td>\n",
       "      <td>13.52780</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21690698</th>\n",
       "      <td>2018-07-06 17:23:19.059</td>\n",
       "      <td>19.95560</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21690699</th>\n",
       "      <td>2018-07-06 17:24:31.421</td>\n",
       "      <td>6.39167</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pub_millis  avg_speed  \\\n",
       "21690695  2018-07-06 17:28:12.166    7.35278   \n",
       "21690696  2018-07-06 17:28:12.867    1.77222   \n",
       "21690697  2018-07-06 16:18:23.454   13.52780   \n",
       "21690698  2018-07-06 17:23:19.059   19.95560   \n",
       "21690699  2018-07-06 17:24:31.421    6.39167   \n",
       "\n",
       "                                                     edges  \n",
       "21690695                                                []  \n",
       "21690696  [(122532560, 122735795), (123129231, 122527731)]  \n",
       "21690697                                                []  \n",
       "21690698                                                []  \n",
       "21690699                                                []  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save state 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'data/jams-edges-{file_num}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:red;'>Note: Finish creating all jams-edges files to continue</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load series of jams-edges files to continue processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteIfExists(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a series of jams-edge files using glob\n",
    "df = pd.DataFrame()\n",
    "df = pd.concat([pd.read_csv(f, header=None) for f in glob.glob('data/jams-edges-*.csv')], ignore_index=True)\n",
    "\n",
    "# pub_millis: dateobject, avg_speed: float, line: list of dict\n",
    "df.columns = ['pub_millis', 'avg_speed', 'edges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-10 23:57:34.974</td>\n",
       "      <td>5.89444</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>[(122663681, 122663684), (122663684, 122663687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-11 00:42:26.705</td>\n",
       "      <td>1.27778</td>\n",
       "      <td>[(60946388, 122688732)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-10 22:45:14.498</td>\n",
       "      <td>1.78889</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-11 00:47:49.429</td>\n",
       "      <td>5.55556</td>\n",
       "      <td>[(21063622, 122814825), (122814825, 60946379),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pub_millis  avg_speed  \\\n",
       "0  2018-04-10 23:57:34.974    5.89444   \n",
       "1  2018-04-11 00:30:30.955    4.35000   \n",
       "2  2018-04-11 00:42:26.705    1.27778   \n",
       "3  2018-04-10 22:45:14.498    1.78889   \n",
       "4  2018-04-11 00:47:49.429    5.55556   \n",
       "\n",
       "                                               edges  \n",
       "0                                                 []  \n",
       "1  [(122663681, 122663684), (122663684, 122663687...  \n",
       "2                            [(60946388, 122688732)]  \n",
       "3                                                 []  \n",
       "4  [(21063622, 122814825), (122814825, 60946379),...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>[(122663681, 122663684), (122663684, 122663687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-11 00:42:26.705</td>\n",
       "      <td>1.27778</td>\n",
       "      <td>[(60946388, 122688732)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-11 00:47:49.429</td>\n",
       "      <td>5.55556</td>\n",
       "      <td>[(21063622, 122814825), (122814825, 60946379),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-11 00:41:03.941</td>\n",
       "      <td>1.14722</td>\n",
       "      <td>[(14940283, 122967892)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-10 23:27:53.283</td>\n",
       "      <td>1.32222</td>\n",
       "      <td>[(122681252, 122681255)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pub_millis  avg_speed  \\\n",
       "0  2018-04-11 00:30:30.955    4.35000   \n",
       "1  2018-04-11 00:42:26.705    1.27778   \n",
       "2  2018-04-11 00:47:49.429    5.55556   \n",
       "3  2018-04-11 00:41:03.941    1.14722   \n",
       "4  2018-04-10 23:27:53.283    1.32222   \n",
       "\n",
       "                                               edges  \n",
       "0  [(122663681, 122663684), (122663684, 122663687...  \n",
       "1                            [(60946388, 122688732)]  \n",
       "2  [(21063622, 122814825), (122814825, 60946379),...  \n",
       "3                            [(14940283, 122967892)]  \n",
       "4                           [(122681252, 122681255)]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with empty edge lists\n",
    "df = df[df['edges'] != '[]'].reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pseudo edge-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict to store key-value pairs of (start_node, end_node): edge_id\n",
    "segments = {}\n",
    "with open('data/segment.csv') as in_file:\n",
    "    for line in in_file:\n",
    "        split_line = line.rstrip().split(',')\n",
    "        \n",
    "        # set node tuple (key) in dict to its rowid (value)\n",
    "        start = int(split_line[1])\n",
    "        end = int(split_line[2])\n",
    "        edge_id = int(split_line[0])\n",
    "        segments[start, end] = edge_id\n",
    "\n",
    "# v = edges_id, k = (start, end)\n",
    "inverted_segments = {v: k for k, v in segments.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pseudo_edge_id(col):\n",
    "    from ast import literal_eval\n",
    "    edge_indexes = []\n",
    "    for edge in literal_eval(col):\n",
    "        # dict.get(item if exist, else default to value)\n",
    "        edge_indexes.append(segments.get(edge, -1))\n",
    "    return edge_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 17min 40.1s\n"
     ]
    }
   ],
   "source": [
    "# map each edge tuple to a pseudo edge id\n",
    "res = dd.from_pandas(df,npartitions=nCores).map_partitions(\n",
    "    lambda _df : _df.apply(\n",
    "        lambda x : create_pseudo_edge_id(x.edges),axis=1), meta=('edges','i8'))\n",
    "\n",
    "# print progress\n",
    "with ProgressBar(dt=0.01):\n",
    "    out = res.compute(scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [116529, 116533, 49632, 116509, 135195, 116518]\n",
       "1                                           [135193]\n",
       "2                               [97216, 275, 108197]\n",
       "3                                           [135466]\n",
       "4                                           [135124]\n",
       "Name: edges, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the pseudo edge id lists to the dataframe\n",
    "df['edge_id'] = pd.Series(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>edges</th>\n",
       "      <th>edge_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>[(122663681, 122663684), (122663684, 122663687...</td>\n",
       "      <td>[116529, 116533, 49632, 116509, 135195, 116518]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-11 00:42:26.705</td>\n",
       "      <td>1.277780</td>\n",
       "      <td>[(60946388, 122688732)]</td>\n",
       "      <td>[135193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-11 00:47:49.429</td>\n",
       "      <td>5.555560</td>\n",
       "      <td>[(21063622, 122814825), (122814825, 60946379),...</td>\n",
       "      <td>[97216, 275, 108197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-11 00:41:03.941</td>\n",
       "      <td>1.147220</td>\n",
       "      <td>[(14940283, 122967892)]</td>\n",
       "      <td>[135466]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-10 23:27:53.283</td>\n",
       "      <td>1.322220</td>\n",
       "      <td>[(122681252, 122681255)]</td>\n",
       "      <td>[135124]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-04-11 00:37:17.085</td>\n",
       "      <td>6.761110</td>\n",
       "      <td>[(123368236, 122928109), (28112699, 123065661)]</td>\n",
       "      <td>[27371, 65706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-04-11 00:05:53.054</td>\n",
       "      <td>2.330560</td>\n",
       "      <td>[(28112695, 122517974)]</td>\n",
       "      <td>[65693]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-04-11 00:30:31.632</td>\n",
       "      <td>4.386110</td>\n",
       "      <td>[(1721407624, 1721407626)]</td>\n",
       "      <td>[39692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-04-11 00:39:39.774</td>\n",
       "      <td>5.255560</td>\n",
       "      <td>[(123368236, 122928109)]</td>\n",
       "      <td>[27371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-04-11 00:08:14.911</td>\n",
       "      <td>3.136110</td>\n",
       "      <td>[(123179440, 15864734), (28112697, 123179450)]</td>\n",
       "      <td>[108527, 65698]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-04-11 00:51:37.521</td>\n",
       "      <td>3.466670</td>\n",
       "      <td>[(123368232, 122690570), (1718125037, 17181250...</td>\n",
       "      <td>[27364, 32316]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-04-10 23:40:47.755</td>\n",
       "      <td>4.161110</td>\n",
       "      <td>[(123154131, 123154134)]</td>\n",
       "      <td>[80910]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-04-11 00:20:05.946</td>\n",
       "      <td>3.627780</td>\n",
       "      <td>[(123140870, 123442824)]</td>\n",
       "      <td>[66748]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-04-11 00:46:29.507</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>[(123442832, 18153980)]</td>\n",
       "      <td>[109917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-04-11 00:20:06.051</td>\n",
       "      <td>3.444440</td>\n",
       "      <td>[(122590171, 122590165)]</td>\n",
       "      <td>[38377]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-04-10 23:29:14.291</td>\n",
       "      <td>3.744440</td>\n",
       "      <td>[(122814858, 122814860), (605262092, 17597292)]</td>\n",
       "      <td>[299, 108428]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-04-10 23:51:05.967</td>\n",
       "      <td>1.494440</td>\n",
       "      <td>[(122657670, 122657672), (122657673, 2995248296)]</td>\n",
       "      <td>[111071, 111080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-04-11 00:31:46.014</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>[(123138587, 123331102)]</td>\n",
       "      <td>[64042]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-04-11 00:37:20.804</td>\n",
       "      <td>1.763890</td>\n",
       "      <td>[(122657668, 122657670), (2995248296, 12265767...</td>\n",
       "      <td>[111067, 127362, 111094]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-04-11 00:13:27.595</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>[(122911563, 26277276)]</td>\n",
       "      <td>[102105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-04-11 00:25:31.223</td>\n",
       "      <td>4.011110</td>\n",
       "      <td>[(17597292, 605262092), (122814704, 1614923794)]</td>\n",
       "      <td>[32735, 139]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-04-10 23:07:27.795</td>\n",
       "      <td>2.061110</td>\n",
       "      <td>[(122671044, 1830231462), (1718304398, 1226568...</td>\n",
       "      <td>[123354, 85912]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-04-11 00:13:25.262</td>\n",
       "      <td>1.327780</td>\n",
       "      <td>[(268645017, 268645369)]</td>\n",
       "      <td>[82013]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-04-11 00:39:37.682</td>\n",
       "      <td>1.452780</td>\n",
       "      <td>[(17677673, 17677675)]</td>\n",
       "      <td>[118564]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-04-11 00:32:03.543</td>\n",
       "      <td>1.172220</td>\n",
       "      <td>[(268372658, 268372661), (268372661, 268372666)]</td>\n",
       "      <td>[70786, 70791]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-04-11 00:24:18.676</td>\n",
       "      <td>2.838890</td>\n",
       "      <td>[(268648453, 2351053338)]</td>\n",
       "      <td>[86389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-04-11 00:37:19.159</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>[(268651410, 26462445), (26462445, 68267399)]</td>\n",
       "      <td>[89388, 121326]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-04-11 00:31:45.677</td>\n",
       "      <td>5.725000</td>\n",
       "      <td>[(122999181, 123154075), (123154076, 123154078)]</td>\n",
       "      <td>[55817, 80841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-04-10 23:39:37.951</td>\n",
       "      <td>2.983330</td>\n",
       "      <td>[(268650702, 268650703)]</td>\n",
       "      <td>[88676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-04-11 00:04:40.438</td>\n",
       "      <td>2.861110</td>\n",
       "      <td>[(1738809277, 20399998)]</td>\n",
       "      <td>[7474]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2018-04-11 00:45:08.713</td>\n",
       "      <td>3.744440</td>\n",
       "      <td>[(1716461325, 1716461357)]</td>\n",
       "      <td>[75832]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2018-04-11 00:32:01.679</td>\n",
       "      <td>4.908330</td>\n",
       "      <td>[(1716287762, 1716287963), (1716287867, 171628...</td>\n",
       "      <td>[28873, 29105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2018-04-11 00:45:06.733</td>\n",
       "      <td>2.136110</td>\n",
       "      <td>[(122647457, 123090498), (123090498, 123353993...</td>\n",
       "      <td>[100087, 13014, 14439]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2018-04-11 00:33:26.018</td>\n",
       "      <td>4.522220</td>\n",
       "      <td>[(123286577, 123153812), (122901111, 123223736)]</td>\n",
       "      <td>[82648, 91512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2018-04-11 00:47:51.723</td>\n",
       "      <td>2.888890</td>\n",
       "      <td>[(1732243688, 1720047674)]</td>\n",
       "      <td>[133549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2018-04-11 00:50:09.844</td>\n",
       "      <td>4.558330</td>\n",
       "      <td>[(216708788, 123192467)]</td>\n",
       "      <td>[47971]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>2018-04-10 23:39:33.386</td>\n",
       "      <td>2.541670</td>\n",
       "      <td>[(122609797, 122609799), (122609808, 21302801)]</td>\n",
       "      <td>[59554, 59566]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2018-04-11 00:46:35.113</td>\n",
       "      <td>3.708330</td>\n",
       "      <td>[(1732243688, 1720047674)]</td>\n",
       "      <td>[133549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2018-04-11 00:35:59.462</td>\n",
       "      <td>3.416670</td>\n",
       "      <td>[(123016427, 123286604), (123286604, 123286607...</td>\n",
       "      <td>[73033, 82689, 82694, 82700, 113401, 82703]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2018-04-11 00:03:19.418</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>[(1774095098, 123639881)]</td>\n",
       "      <td>[35481]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2018-04-11 00:52:50.130</td>\n",
       "      <td>1.672220</td>\n",
       "      <td>[(122645236, 68267399)]</td>\n",
       "      <td>[98320]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2018-04-11 00:45:04.366</td>\n",
       "      <td>3.155560</td>\n",
       "      <td>[(123564065, 122437468)]</td>\n",
       "      <td>[99382]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>2018-04-11 00:45:10.883</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>[(123564065, 122437468)]</td>\n",
       "      <td>[99382]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>2018-04-11 00:52:52.892</td>\n",
       "      <td>2.025000</td>\n",
       "      <td>[(122437468, 122437462)]</td>\n",
       "      <td>[15376]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>2018-04-11 00:47:51.763</td>\n",
       "      <td>3.338890</td>\n",
       "      <td>[(122437468, 122437462)]</td>\n",
       "      <td>[15376]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>2018-04-11 00:26:48.263</td>\n",
       "      <td>2.194440</td>\n",
       "      <td>[(122594944, 122594946), (122594946, 122594949...</td>\n",
       "      <td>[43722, 43725, 43737, 35106, 43750]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2018-04-11 00:34:44.736</td>\n",
       "      <td>1.538890</td>\n",
       "      <td>[(1918885049, 122742350)]</td>\n",
       "      <td>[127400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>2018-04-11 00:32:06.715</td>\n",
       "      <td>1.683330</td>\n",
       "      <td>[(123463246, 123463248), (123463251, 122379124)]</td>\n",
       "      <td>[130314, 130329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>2018-04-11 00:10:53.978</td>\n",
       "      <td>2.305560</td>\n",
       "      <td>[(122920979, 123614155)]</td>\n",
       "      <td>[112139]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2018-04-11 00:50:18.772</td>\n",
       "      <td>2.566670</td>\n",
       "      <td>[(123571467, 123614155)]</td>\n",
       "      <td>[107497]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>2018-04-11 00:51:36.237</td>\n",
       "      <td>2.594440</td>\n",
       "      <td>[(123564044, 122659539), (123300502, 123567423)]</td>\n",
       "      <td>[99328, 98219]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>2018-04-11 00:52:52.672</td>\n",
       "      <td>7.213890</td>\n",
       "      <td>[(123071508, 123756397)]</td>\n",
       "      <td>[132006]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>2018-04-11 00:45:05.359</td>\n",
       "      <td>7.233330</td>\n",
       "      <td>[(1433929149, 122779455)]</td>\n",
       "      <td>[1681]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>2018-04-11 00:30:29.605</td>\n",
       "      <td>3.380560</td>\n",
       "      <td>[(123044784, 613373175)]</td>\n",
       "      <td>[104918]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>2018-04-11 00:43:42.086</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>[(122684540, 123053759)]</td>\n",
       "      <td>[1263]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>2018-04-11 00:09:32.599</td>\n",
       "      <td>4.283330</td>\n",
       "      <td>[(1732243601, 63068674)]</td>\n",
       "      <td>[133328]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>2018-04-11 00:33:24.066</td>\n",
       "      <td>3.177780</td>\n",
       "      <td>[(63068610, 21306060)]</td>\n",
       "      <td>[21668]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>2018-04-11 00:40:56.539</td>\n",
       "      <td>2.366670</td>\n",
       "      <td>[(20400292, 123241961), (123241963, 123241965)...</td>\n",
       "      <td>[88644, 33403, 33406]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>2018-04-11 00:45:08.551</td>\n",
       "      <td>2.102780</td>\n",
       "      <td>[(348121996, 4015372463), (1732243576, 4015372...</td>\n",
       "      <td>[131911, 133254]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>2018-04-11 00:26:47.475</td>\n",
       "      <td>2.480560</td>\n",
       "      <td>[(21098484, 21098483), (21098486, 123183767)]</td>\n",
       "      <td>[132949, 132958]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pub_millis  avg_speed  \\\n",
       "0    2018-04-11 00:30:30.955   4.350000   \n",
       "1    2018-04-11 00:42:26.705   1.277780   \n",
       "2    2018-04-11 00:47:49.429   5.555560   \n",
       "3    2018-04-11 00:41:03.941   1.147220   \n",
       "4    2018-04-10 23:27:53.283   1.322220   \n",
       "5    2018-04-11 00:37:17.085   6.761110   \n",
       "6    2018-04-11 00:05:53.054   2.330560   \n",
       "7    2018-04-11 00:30:31.632   4.386110   \n",
       "8    2018-04-11 00:39:39.774   5.255560   \n",
       "9    2018-04-11 00:08:14.911   3.136110   \n",
       "10   2018-04-11 00:51:37.521   3.466670   \n",
       "11   2018-04-10 23:40:47.755   4.161110   \n",
       "12   2018-04-11 00:20:05.946   3.627780   \n",
       "13   2018-04-11 00:46:29.507   0.788889   \n",
       "14   2018-04-11 00:20:06.051   3.444440   \n",
       "15   2018-04-10 23:29:14.291   3.744440   \n",
       "16   2018-04-10 23:51:05.967   1.494440   \n",
       "17   2018-04-11 00:31:46.014   0.619444   \n",
       "18   2018-04-11 00:37:20.804   1.763890   \n",
       "19   2018-04-11 00:13:27.595   0.994444   \n",
       "20   2018-04-11 00:25:31.223   4.011110   \n",
       "21   2018-04-10 23:07:27.795   2.061110   \n",
       "22   2018-04-11 00:13:25.262   1.327780   \n",
       "23   2018-04-11 00:39:37.682   1.452780   \n",
       "24   2018-04-11 00:32:03.543   1.172220   \n",
       "25   2018-04-11 00:24:18.676   2.838890   \n",
       "26   2018-04-11 00:37:19.159   4.950000   \n",
       "27   2018-04-11 00:31:45.677   5.725000   \n",
       "28   2018-04-10 23:39:37.951   2.983330   \n",
       "29   2018-04-11 00:04:40.438   2.861110   \n",
       "..                       ...        ...   \n",
       "570  2018-04-11 00:45:08.713   3.744440   \n",
       "571  2018-04-11 00:32:01.679   4.908330   \n",
       "572  2018-04-11 00:45:06.733   2.136110   \n",
       "573  2018-04-11 00:33:26.018   4.522220   \n",
       "574  2018-04-11 00:47:51.723   2.888890   \n",
       "575  2018-04-11 00:50:09.844   4.558330   \n",
       "576  2018-04-10 23:39:33.386   2.541670   \n",
       "577  2018-04-11 00:46:35.113   3.708330   \n",
       "578  2018-04-11 00:35:59.462   3.416670   \n",
       "579  2018-04-11 00:03:19.418   4.550000   \n",
       "580  2018-04-11 00:52:50.130   1.672220   \n",
       "581  2018-04-11 00:45:04.366   3.155560   \n",
       "582  2018-04-11 00:45:10.883   2.150000   \n",
       "583  2018-04-11 00:52:52.892   2.025000   \n",
       "584  2018-04-11 00:47:51.763   3.338890   \n",
       "585  2018-04-11 00:26:48.263   2.194440   \n",
       "586  2018-04-11 00:34:44.736   1.538890   \n",
       "587  2018-04-11 00:32:06.715   1.683330   \n",
       "588  2018-04-11 00:10:53.978   2.305560   \n",
       "589  2018-04-11 00:50:18.772   2.566670   \n",
       "590  2018-04-11 00:51:36.237   2.594440   \n",
       "591  2018-04-11 00:52:52.672   7.213890   \n",
       "592  2018-04-11 00:45:05.359   7.233330   \n",
       "593  2018-04-11 00:30:29.605   3.380560   \n",
       "594  2018-04-11 00:43:42.086   3.050000   \n",
       "595  2018-04-11 00:09:32.599   4.283330   \n",
       "596  2018-04-11 00:33:24.066   3.177780   \n",
       "597  2018-04-11 00:40:56.539   2.366670   \n",
       "598  2018-04-11 00:45:08.551   2.102780   \n",
       "599  2018-04-11 00:26:47.475   2.480560   \n",
       "\n",
       "                                                 edges  \\\n",
       "0    [(122663681, 122663684), (122663684, 122663687...   \n",
       "1                              [(60946388, 122688732)]   \n",
       "2    [(21063622, 122814825), (122814825, 60946379),...   \n",
       "3                              [(14940283, 122967892)]   \n",
       "4                             [(122681252, 122681255)]   \n",
       "5      [(123368236, 122928109), (28112699, 123065661)]   \n",
       "6                              [(28112695, 122517974)]   \n",
       "7                           [(1721407624, 1721407626)]   \n",
       "8                             [(123368236, 122928109)]   \n",
       "9       [(123179440, 15864734), (28112697, 123179450)]   \n",
       "10   [(123368232, 122690570), (1718125037, 17181250...   \n",
       "11                            [(123154131, 123154134)]   \n",
       "12                            [(123140870, 123442824)]   \n",
       "13                             [(123442832, 18153980)]   \n",
       "14                            [(122590171, 122590165)]   \n",
       "15     [(122814858, 122814860), (605262092, 17597292)]   \n",
       "16   [(122657670, 122657672), (122657673, 2995248296)]   \n",
       "17                            [(123138587, 123331102)]   \n",
       "18   [(122657668, 122657670), (2995248296, 12265767...   \n",
       "19                             [(122911563, 26277276)]   \n",
       "20    [(17597292, 605262092), (122814704, 1614923794)]   \n",
       "21   [(122671044, 1830231462), (1718304398, 1226568...   \n",
       "22                            [(268645017, 268645369)]   \n",
       "23                              [(17677673, 17677675)]   \n",
       "24    [(268372658, 268372661), (268372661, 268372666)]   \n",
       "25                           [(268648453, 2351053338)]   \n",
       "26       [(268651410, 26462445), (26462445, 68267399)]   \n",
       "27    [(122999181, 123154075), (123154076, 123154078)]   \n",
       "28                            [(268650702, 268650703)]   \n",
       "29                            [(1738809277, 20399998)]   \n",
       "..                                                 ...   \n",
       "570                         [(1716461325, 1716461357)]   \n",
       "571  [(1716287762, 1716287963), (1716287867, 171628...   \n",
       "572  [(122647457, 123090498), (123090498, 123353993...   \n",
       "573   [(123286577, 123153812), (122901111, 123223736)]   \n",
       "574                         [(1732243688, 1720047674)]   \n",
       "575                           [(216708788, 123192467)]   \n",
       "576    [(122609797, 122609799), (122609808, 21302801)]   \n",
       "577                         [(1732243688, 1720047674)]   \n",
       "578  [(123016427, 123286604), (123286604, 123286607...   \n",
       "579                          [(1774095098, 123639881)]   \n",
       "580                            [(122645236, 68267399)]   \n",
       "581                           [(123564065, 122437468)]   \n",
       "582                           [(123564065, 122437468)]   \n",
       "583                           [(122437468, 122437462)]   \n",
       "584                           [(122437468, 122437462)]   \n",
       "585  [(122594944, 122594946), (122594946, 122594949...   \n",
       "586                          [(1918885049, 122742350)]   \n",
       "587   [(123463246, 123463248), (123463251, 122379124)]   \n",
       "588                           [(122920979, 123614155)]   \n",
       "589                           [(123571467, 123614155)]   \n",
       "590   [(123564044, 122659539), (123300502, 123567423)]   \n",
       "591                           [(123071508, 123756397)]   \n",
       "592                          [(1433929149, 122779455)]   \n",
       "593                           [(123044784, 613373175)]   \n",
       "594                           [(122684540, 123053759)]   \n",
       "595                           [(1732243601, 63068674)]   \n",
       "596                             [(63068610, 21306060)]   \n",
       "597  [(20400292, 123241961), (123241963, 123241965)...   \n",
       "598  [(348121996, 4015372463), (1732243576, 4015372...   \n",
       "599      [(21098484, 21098483), (21098486, 123183767)]   \n",
       "\n",
       "                                             edge_id  \n",
       "0    [116529, 116533, 49632, 116509, 135195, 116518]  \n",
       "1                                           [135193]  \n",
       "2                               [97216, 275, 108197]  \n",
       "3                                           [135466]  \n",
       "4                                           [135124]  \n",
       "5                                     [27371, 65706]  \n",
       "6                                            [65693]  \n",
       "7                                            [39692]  \n",
       "8                                            [27371]  \n",
       "9                                    [108527, 65698]  \n",
       "10                                    [27364, 32316]  \n",
       "11                                           [80910]  \n",
       "12                                           [66748]  \n",
       "13                                          [109917]  \n",
       "14                                           [38377]  \n",
       "15                                     [299, 108428]  \n",
       "16                                  [111071, 111080]  \n",
       "17                                           [64042]  \n",
       "18                          [111067, 127362, 111094]  \n",
       "19                                          [102105]  \n",
       "20                                      [32735, 139]  \n",
       "21                                   [123354, 85912]  \n",
       "22                                           [82013]  \n",
       "23                                          [118564]  \n",
       "24                                    [70786, 70791]  \n",
       "25                                           [86389]  \n",
       "26                                   [89388, 121326]  \n",
       "27                                    [55817, 80841]  \n",
       "28                                           [88676]  \n",
       "29                                            [7474]  \n",
       "..                                               ...  \n",
       "570                                          [75832]  \n",
       "571                                   [28873, 29105]  \n",
       "572                           [100087, 13014, 14439]  \n",
       "573                                   [82648, 91512]  \n",
       "574                                         [133549]  \n",
       "575                                          [47971]  \n",
       "576                                   [59554, 59566]  \n",
       "577                                         [133549]  \n",
       "578      [73033, 82689, 82694, 82700, 113401, 82703]  \n",
       "579                                          [35481]  \n",
       "580                                          [98320]  \n",
       "581                                          [99382]  \n",
       "582                                          [99382]  \n",
       "583                                          [15376]  \n",
       "584                                          [15376]  \n",
       "585              [43722, 43725, 43737, 35106, 43750]  \n",
       "586                                         [127400]  \n",
       "587                                 [130314, 130329]  \n",
       "588                                         [112139]  \n",
       "589                                         [107497]  \n",
       "590                                   [99328, 98219]  \n",
       "591                                         [132006]  \n",
       "592                                           [1681]  \n",
       "593                                         [104918]  \n",
       "594                                           [1263]  \n",
       "595                                         [133328]  \n",
       "596                                          [21668]  \n",
       "597                            [88644, 33403, 33406]  \n",
       "598                                 [131911, 133254]  \n",
       "599                                 [132949, 132958]  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop edges column from dataframe and reset index\n",
    "df = df.drop(['edges'], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>edge_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>[116529, 116533, 49632, 116509, 135195, 116518]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-11 00:42:26.705</td>\n",
       "      <td>1.27778</td>\n",
       "      <td>[135193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-11 00:47:49.429</td>\n",
       "      <td>5.55556</td>\n",
       "      <td>[97216, 275, 108197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-11 00:41:03.941</td>\n",
       "      <td>1.14722</td>\n",
       "      <td>[135466]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-10 23:27:53.283</td>\n",
       "      <td>1.32222</td>\n",
       "      <td>[135124]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pub_millis  avg_speed  \\\n",
       "0  2018-04-11 00:30:30.955    4.35000   \n",
       "1  2018-04-11 00:42:26.705    1.27778   \n",
       "2  2018-04-11 00:47:49.429    5.55556   \n",
       "3  2018-04-11 00:41:03.941    1.14722   \n",
       "4  2018-04-10 23:27:53.283    1.32222   \n",
       "\n",
       "                                           edge_id  \n",
       "0  [116529, 116533, 49632, 116509, 135195, 116518]  \n",
       "1                                         [135193]  \n",
       "2                             [97216, 275, 108197]  \n",
       "3                                         [135466]  \n",
       "4                                         [135124]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the results of the drop operation\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save state 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/jams-edgeid.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload jams-edgeid to continue processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteIfExists(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('data/jams-edgeid.csv', header=None, names=['pub_millis', 'avg_speed', 'edge_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from ast import literal_eval\n",
    "df['edge_id'] = df['edge_id'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the list of edge ids into multiple rows (one row per edge id)\n",
    "a = 'pub_millis'\n",
    "b = 'edge_id'\n",
    "c = 'avg_speed'\n",
    "\n",
    "speed_df = pd.DataFrame({'pub_millis': np.repeat(df[a].values, df[b].str.len()),\n",
    "                        'avg_speed': np.repeat(df[c].values, df[b].str.len()),\n",
    "                        'edge_id': np.concatenate(df[b].values)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>edge_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>[116529, 116533, 49632, 116509, 135195, 116518]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-11 00:42:26.705</td>\n",
       "      <td>1.27778</td>\n",
       "      <td>[135193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-11 00:47:49.429</td>\n",
       "      <td>5.55556</td>\n",
       "      <td>[97216, 275, 108197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-11 00:41:03.941</td>\n",
       "      <td>1.14722</td>\n",
       "      <td>[135466]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-10 23:27:53.283</td>\n",
       "      <td>1.32222</td>\n",
       "      <td>[135124]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pub_millis  avg_speed  \\\n",
       "0  2018-04-11 00:30:30.955    4.35000   \n",
       "1  2018-04-11 00:42:26.705    1.27778   \n",
       "2  2018-04-11 00:47:49.429    5.55556   \n",
       "3  2018-04-11 00:41:03.941    1.14722   \n",
       "4  2018-04-10 23:27:53.283    1.32222   \n",
       "\n",
       "                                           edge_id  \n",
       "0  [116529, 116533, 49632, 116509, 135195, 116518]  \n",
       "1                                         [135193]  \n",
       "2                             [97216, 275, 108197]  \n",
       "3                                         [135466]  \n",
       "4                                         [135124]  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show original state of df before splitting edge id into multiple rows\n",
    "df.head()\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>edge_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35</td>\n",
       "      <td>116529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35</td>\n",
       "      <td>116533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35</td>\n",
       "      <td>49632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35</td>\n",
       "      <td>116509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-11 00:30:30.955</td>\n",
       "      <td>4.35</td>\n",
       "      <td>135195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pub_millis  avg_speed  edge_id\n",
       "0  2018-04-11 00:30:30.955       4.35   116529\n",
       "1  2018-04-11 00:30:30.955       4.35   116533\n",
       "2  2018-04-11 00:30:30.955       4.35    49632\n",
       "3  2018-04-11 00:30:30.955       4.35   116509\n",
       "4  2018-04-11 00:30:30.955       4.35   135195"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the result of splitting the edge ids into multiple rows\n",
    "speed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define interval for time series\n",
    "interval = 10\n",
    "interval_string = str(interval) + 'min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round each time in the dataset to the nearest interval\n",
    "speed_df['pub_millis'] = pd.to_datetime(speed_df['pub_millis']).dt.round(interval_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby edge and time then find the mean of speeds \n",
    "# for rows with the same timestamp and edge id\n",
    "speed_df = speed_df.groupby(['pub_millis', 'edge_id'], as_index=False)['avg_speed'].mean()\n",
    "speed_df = speed_df.sort_values(['edge_id', 'pub_millis'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all rows that have an edge_id of -1 because they weren't found\n",
    "speed_df = speed_df[speed_df['edge_id'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-18 04:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.811110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-25 06:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.974070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-24 01:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.516670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-06 04:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.227780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-22 15:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.561110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-05-23 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-06-25 09:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.636805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-12-15 02:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2.444841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-07 07:30:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2.791358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-21 10:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2.645000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pub_millis  edge_id  avg_speed\n",
       "0 2017-12-18 04:30:00        2   1.811110\n",
       "1 2017-12-25 06:30:00        2   1.974070\n",
       "2 2018-02-24 01:30:00        2   2.516670\n",
       "3 2018-03-06 04:30:00        2   2.227780\n",
       "4 2018-03-22 15:30:00        2   2.561110\n",
       "5 2018-05-23 01:00:00        2   1.600000\n",
       "6 2018-06-25 09:00:00        2   1.636805\n",
       "7 2017-12-15 02:00:00        5   2.444841\n",
       "8 2018-01-07 07:30:00        5   2.791358\n",
       "9 2018-01-21 10:00:00        5   2.645000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save state 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df.to_csv(f'data/jams-speed-{interval}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload jams-speed to continue processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteIfExists(speed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('data/jams-speed.csv', header=None)\n",
    "\n",
    "# pub_millis: dateobject, avg_speed: float, line: list of dict\n",
    "df.columns = ['pub_millis', 'edge_id', 'avg_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create segments dict using segment.csv\n",
    "segments = {}\n",
    "with open('data/segment.csv') as in_file:\n",
    "    for line in in_file:\n",
    "        split_line = line.rstrip().split(',')\n",
    "        \n",
    "        # set the key of dict to be the edge tuple, and the value to be the row id\n",
    "        segments[(int(split_line[1]), int(split_line[2]))] = int(split_line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-18 04:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.81111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-25 06:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.97407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-24 01:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.51667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-06 04:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.22778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-22 15:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.56111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pub_millis  edge_id  avg_speed\n",
       "0 2017-12-18 04:30:00        2    1.81111\n",
       "1 2017-12-25 06:30:00        2    1.97407\n",
       "2 2018-02-24 01:30:00        2    2.51667\n",
       "3 2018-03-06 04:30:00        2    2.22778\n",
       "4 2018-03-22 15:30:00        2    2.56111"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4214, 6273, 6274, 7997, 14074]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter edge-ids for financial district\n",
    "financial_district_ids = []\n",
    "with open('data/selSegs_1.csv') as in_file:\n",
    "    for line in in_file:\n",
    "        financial_district_ids.append(int(line.rstrip()))\n",
    "        \n",
    "financial_district_ids[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of edge ids and tuple data for financial district\n",
    "district_segments = {}\n",
    "with open('data/segment.csv') as in_file:\n",
    "    for line in in_file:\n",
    "        split_line = line.rstrip().split(',')\n",
    "        \n",
    "        if int(split_line[0]) in financial_district_ids:\n",
    "            # set the key of dict to be the edge tuple, and the value to be the row id\n",
    "            district_segments[int(split_line[0])] = (int(split_line[1]), int(split_line[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4214,   6274,  26311,  26312,  41496,  41497,  42385,  42386,\n",
       "        58388,  59425,  59426,  59449,  59456,  59496,  60896,  60898,\n",
       "        63235,  63236,  63245,  63246,  63247,  68997,  68998,  68999,\n",
       "        69733,  69735,  77169,  77174,  77176,  83353,  83813,  88491,\n",
       "        88492,  88493,  88827,  89809,  90176,  90177,  90178,  90442,\n",
       "        90443,  90444,  94602, 118097, 120247, 120563, 120572, 132535,\n",
       "       132544, 132545, 134118, 134177], dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter dataframe by all edge ids that exist in the financial district\n",
    "district_df = df[df['edge_id'].isin(financial_district_ids)]\n",
    "district_df['edge_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137283"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "district_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>362127</th>\n",
       "      <td>2017-12-12 02:30:00</td>\n",
       "      <td>4214</td>\n",
       "      <td>1.819445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362128</th>\n",
       "      <td>2017-12-13 00:00:00</td>\n",
       "      <td>4214</td>\n",
       "      <td>1.745554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362129</th>\n",
       "      <td>2017-12-13 00:30:00</td>\n",
       "      <td>4214</td>\n",
       "      <td>1.936668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362130</th>\n",
       "      <td>2017-12-13 01:00:00</td>\n",
       "      <td>4214</td>\n",
       "      <td>1.794841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362131</th>\n",
       "      <td>2017-12-13 01:30:00</td>\n",
       "      <td>4214</td>\n",
       "      <td>1.785187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pub_millis  edge_id  avg_speed\n",
       "362127 2017-12-12 02:30:00     4214   1.819445\n",
       "362128 2017-12-13 00:00:00     4214   1.745554\n",
       "362129 2017-12-13 00:30:00     4214   1.936668\n",
       "362130 2017-12-13 01:00:00     4214   1.794841\n",
       "362131 2017-12-13 01:30:00     4214   1.785187"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "district_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save state 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df.to_csv(f'data/jams-district-{interval}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values using KNN Regessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteIfExists(district_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define interval for time series\n",
    "interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv(f'data/jams-district-{interval}.csv', dtype={'avg_speed':'float64'}, header=None,\n",
    "                     names=['pub_millis', 'edge_id', 'avg_speed'],\n",
    "                     converters={'edge_id':literal_eval, 'pub_millis':pd.to_datetime})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of edges\n",
    "segments = {}\n",
    "with open('data/segment.csv') as in_file:\n",
    "    for line in in_file:\n",
    "        split_line = line.rstrip().split(',')\n",
    "        \n",
    "        # set the key of dict to be the edge tuple, and the value to be the row id\n",
    "        segments[(int(split_line[1]), int(split_line[2]))] = int(split_line[0])\n",
    "\n",
    "# invert segments dict \n",
    "inverted_segments = {v: k for k, v in segments.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format data into time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload road network\n",
    "G = ox.graph_from_place('Los Angeles City, Los Angeles, CA',network_type='drive')\n",
    "district_df = pd.DataFrame(columns=['pub_millis', 'edge_id', 'avg_speed'])\n",
    "\n",
    "# convert pub_millis to datetime\n",
    "df['pub_millis'] = pd.to_datetime(df['pub_millis'])\n",
    "\n",
    "# find earliest time and use as starting pseudo-index\n",
    "start_time = df['pub_millis'].min()\n",
    "\n",
    "# total number of intervals = (60 minutes / (m minutes per interval)) * (24 hours/day) * (d days)\n",
    "# currently generating 44 days worth of data\n",
    "data_points = int((60 / int(interval)) * 24 * 44)\n",
    "data = [{} for _ in range(data_points)]\n",
    "\n",
    "# initialize previous_edge_id\n",
    "previous_edge_id = df.iloc[0]['edge_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show starting time\n",
    "start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the ending time based on the total number of intervals for a segment\n",
    "end_time = start_time + np.timedelta64(interval * (data_points - 1), 'm')\n",
    "end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data to only include data points before the end time\n",
    "df = df[df['pub_millis'] < end_time]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify where there are missing data and fill with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "\n",
    "    # find matching edge_id\n",
    "    if previous_edge_id == row['edge_id']:\n",
    "        \n",
    "        # index = (total_seconds / (60 seconds/min * interval)) % data_points\n",
    "        delta_time = row['pub_millis'] - start_time\n",
    "        \n",
    "        data[int((delta_time.total_seconds() / (60.0 * interval)) % data_points)] = {\n",
    "            'pub_millis': row['pub_millis'],\n",
    "            'edge_id': row['edge_id'],\n",
    "            'avg_speed': row['avg_speed']\n",
    "        }\n",
    "        \n",
    "    else:  # fill in missing data with empty string\n",
    "        for index in range(data_points):\n",
    "            if data[index] == {}:\n",
    "                data[index] = {\n",
    "                    'pub_millis': start_time + np.timedelta64(interval * index, 'm'),\n",
    "                    'edge_id': previous_edge_id,\n",
    "                    'avg_speed': ''\n",
    "                }\n",
    "\n",
    "        # append edge data to dataframe\n",
    "        district_df = district_df.append(pd.DataFrame.from_dict(data), sort=False).reset_index(drop=True)\n",
    "\n",
    "        # update previous edge\n",
    "        previous_edge_id = row['edge_id']\n",
    "\n",
    "        # reset data because data list is only associated with one edge at a time\n",
    "        data = [{} for _ in range(data_points)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accounts for the last edge id from the dataframe \n",
    "for index in range(data_points):\n",
    "    if data[index] == {}:\n",
    "        data[index] = {\n",
    "            'pub_millis': start_time + np.timedelta64(interval * index, 'm'),\n",
    "            'edge_id': previous_edge_id,\n",
    "            'avg_speed': ''\n",
    "        }\n",
    "\n",
    "# append edge data to dataframe\n",
    "district_df = district_df.append(pd.DataFrame.from_dict(data), sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of pseudo-edge-ids for financial district\n",
    "financial_district_ids = []\n",
    "edge_count = 0\n",
    "\n",
    "with open('data/selSegs_1.csv') as in_file:\n",
    "    for line in in_file:\n",
    "        financial_district_ids.append(int(line.rstrip()))\n",
    "        edge_count += 1\n",
    "\n",
    "print(edge_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first ten ids of financial district\n",
    "financial_district_ids[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify edge ids are in financial district\n",
    "district_df = district_df[district_df['edge_id'].isin(financial_district_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if edge ids are accounted for, then remove from financial_district_ids\n",
    "for district_id in district_df['edge_id'].unique().tolist():\n",
    "    try: \n",
    "        financial_district_ids.remove(district_id)\n",
    "    except: # ignore any ids that are not in financial district\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the edge ids that need to be computed\n",
    "print(financial_district_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of edge ids with pairs of start and end nodes for financial district\n",
    "district_segments = {}\n",
    "with open('data/segment.csv') as in_file:\n",
    "    for line in in_file:\n",
    "        split_line = line.rstrip().split(',')\n",
    "        \n",
    "        if int(split_line[0]) in financial_district_ids:\n",
    "        \n",
    "            # set the key of dict to be the row id, and the value to be the start and end node pair\n",
    "            district_segments[int(split_line[0])] = (int(split_line[1]), int(split_line[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in missing data with empty string\n",
    "data = [{} for _ in range(data_points)]\n",
    "\n",
    "for district_id in financial_district_ids:\n",
    "    for index in range(data_points):\n",
    "        if data[index] == {}:\n",
    "            data[index] = {\n",
    "                'pub_millis': start_time + np.timedelta64(interval * index, 'm'),\n",
    "                'edge_id': district_id,\n",
    "                'avg_speed': ''\n",
    "            }\n",
    "\n",
    "    # append edge data to dataframe\n",
    "    district_df = district_df.append(pd.DataFrame.from_dict(data), sort=False).reset_index(drop=True)\n",
    "\n",
    "    # update previous edge\n",
    "    data = [{} for _ in range(data_points)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time of Day labels:\n",
    "# 4 <= em < 6 (early morning)\n",
    "# 6 <= mr < 9 (morning rush)\n",
    "# 9 <= m < 12 (morning)\n",
    "# 12 <= a < 15 (afternoon)\n",
    "# 15 <= ar < 19 (afternoon rush)\n",
    "# 19 <= n < 22 (night)\n",
    "# 22 <= nn < 4 (night night)\n",
    "\n",
    "time_of_day_labels = []\n",
    "hour_of_day = -1\n",
    "\n",
    "day_of_week_labels = []\n",
    "day_of_week = -1\n",
    "\n",
    "season_labels = []\n",
    "month = -1\n",
    "\n",
    "for index, row in district_df.iterrows():\n",
    "    # create labels for hour of day\n",
    "    hour_of_day = row['pub_millis'].hour\n",
    "    \n",
    "    if hour_of_day >= 4 and hour_of_day < 6:\n",
    "        time_of_day_labels.append(\"em\")\n",
    "        \n",
    "    elif hour_of_day >= 6 and hour_of_day < 9:\n",
    "        time_of_day_labels.append(\"mr\")\n",
    "        \n",
    "    elif hour_of_day >= 9 and hour_of_day < 12:\n",
    "        time_of_day_labels.append(\"m\")\n",
    "        \n",
    "    elif hour_of_day >= 12 and hour_of_day < 15:\n",
    "        time_of_day_labels.append(\"a\")\n",
    "        \n",
    "    elif hour_of_day >= 15 and hour_of_day < 19:\n",
    "        time_of_day_labels.append(\"ar\")\n",
    "        \n",
    "    elif hour_of_day >= 19 and hour_of_day < 22:\n",
    "        time_of_day_labels.append(\"n\")\n",
    "        \n",
    "    else: # the time is between 22 - 24 or 1 - 3\n",
    "        time_of_day_labels.append(\"nn\")\n",
    "    \n",
    "    \n",
    "    # create labels for day of the week\n",
    "    day_of_week = row['pub_millis'].dayofweek\n",
    "    \n",
    "    if day_of_week is 0:\n",
    "        day_of_week_labels.append(\"mon\")\n",
    "        \n",
    "    elif day_of_week >= 1 and day_of_week <= 3:\n",
    "        day_of_week_labels.append(\"tues_wed_thur\")\n",
    "        \n",
    "    elif day_of_week is 4:\n",
    "        day_of_week_labels.append(\"fri\")\n",
    "        \n",
    "    elif day_of_week is 5:\n",
    "        day_of_week_labels.append(\"sat\")\n",
    "        \n",
    "    elif day_of_week is 6:\n",
    "        day_of_week_labels.append(\"sun\")\n",
    "        \n",
    "    # create labels for season\n",
    "    month = row['pub_millis'].month\n",
    "    \n",
    "    if month >= 3 and month <= 5:\n",
    "        season_labels.append(\"spring\")\n",
    "        \n",
    "    elif month >= 6 and month <= 8:\n",
    "        season_labels.append(\"summer\")\n",
    "        \n",
    "    elif month >= 9 and month <= 11:\n",
    "        season_labels.append(\"fall\")\n",
    "    \n",
    "    else: # the month is 12, 1, or 2\n",
    "        season_labels.append(\"winter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the features to create new columns\n",
    "time_of_day_encoded = pd.get_dummies(pd.Series(time_of_day_labels))\n",
    "day_of_week_encoded = pd.get_dummies(pd.Series(day_of_week_labels))\n",
    "season_encoded = pd.get_dummies(pd.Series(season_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the indexes to prevent concatenation errors\n",
    "district_df.reset_index(drop=True, inplace=True)\n",
    "time_of_day_encoded.reset_index(drop=True, inplace=True)\n",
    "day_of_week_encoded.reset_index(drop=True, inplace=True)\n",
    "season_encoded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "district_df = pd.concat([district_df, time_of_day_encoded, day_of_week_encoded, season_encoded], axis=1)\n",
    "district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df = district_df.drop('winter', 1)\n",
    "district_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df = pd.concat([district_df, pd.get_dummies(district_df['edge_id'])], axis=1)\n",
    "district_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df = district_df.drop('edge_id', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train KNN to perform data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = district_df[district_df['avg_speed'] != '']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = district_df[district_df['avg_speed'] == '']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['pub_millis', 'avg_speed'])\n",
    "y_train = train_df['avg_speed'].values.astype(float)\n",
    "\n",
    "X_test = test_df.drop(columns=['pub_millis', 'avg_speed'])\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsRegressor(n_neighbors = 3)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append predicted values to fill in missing speed values\n",
    "test_df['avg_speed'] = y_pred\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df = pd.concat([train_df, test_df], axis=0)\n",
    "filled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = filled_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we aren't using anymore\n",
    "save_df = save_df.drop(save_df.columns[2:14], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_encode = save_df[save_df==1].stack().reset_index().drop(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_encode = reverse_encode.drop(reverse_encode.columns[0], axis=1)\n",
    "reverse_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df.reset_index(drop=True, inplace=True)\n",
    "reverse_encode.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_result_df = pd.concat([save_df, reverse_encode], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_result_df = imputed_result_df.drop(imputed_result_df.columns[2:113], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_result_df = imputed_result_df.rename(columns={'level_1': 'edge_id'})\n",
    "imputed_result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_result_df = imputed_result_df.sort_values(by=['edge_id', 'pub_millis']).reset_index(drop=True)\n",
    "imputed_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix order of columns to match expected file structure\n",
    "imputed_result_df = imputed_result_df[['pub_millis','edge_id','avg_speed']]\n",
    "imputed_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results in file\n",
    "imputed_result_df.to_csv(f'data/financial_district_{interval}_knn.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
